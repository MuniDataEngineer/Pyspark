# 📁 Log File Reader and Transformer using PySpark

## 📌 Description
This project reads raw `.log` files and processes them using **PySpark** to extract structured information. 
It's useful for preparing the data for downstream analytics or storage systems.

## 🛠️ Tech Stack
- Python
- Apache Spark (PySpark)
- Regular Expressions (`re`)
- SparkSession

## 📁 Folder Structure
`logFileAnalyzer/`
`├── main.py # Main script to read and process log files using PySpark`
`├── requirements.txt # Required Python packages`
`└── data/`
`└── sample.log # Sample log file`

## ▶️ How to Run 
⚠️ **Important:** Run this notebook in Google Colab for the best experience.
1. Install dependencies:
!pip install -r requirements.txt
2. Clone the repository:
!git clone https://github.com/MuniDataEngineer/Pyspark.git
3. Run the main.py file:
%run /content/Pyspark/logFileAnalyzer/main.py

##🌐Colab
🔗 https://colab.research.google.com/

