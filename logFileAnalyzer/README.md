# ğŸ“ Log File Reader and Transformer using PySpark

## ğŸ“Œ Description
This project reads raw `.log` files and processes them using **PySpark** to extract structured information. 
It's useful for preparing the data for downstream analytics or storage systems.

## ğŸ› ï¸ Tech Stack
- Python
- Apache Spark (PySpark)
- Regular Expressions (`re`)
- SparkSession

## ğŸ“ Folder Structure
`logFileAnalyzer/`
`â”œâ”€â”€ main.py # Main script to read and process log files using PySpark`
`â”œâ”€â”€ requirements.txt # Required Python packages`
`â””â”€â”€ data/`
`â””â”€â”€ sample.log # Sample log file`

## â–¶ï¸ How to Run 
âš ï¸ **Important:** Run this notebook in Google Colab for the best experience.
1. Install dependencies:
!pip install -r requirements.txt
2. Clone the repository:
!git clone https://github.com/MuniDataEngineer/Pyspark.git
3. Run the main.py file:
%run /content/Pyspark/logFileAnalyzer/main.py

##ğŸŒColab
ğŸ”— https://colab.research.google.com/

